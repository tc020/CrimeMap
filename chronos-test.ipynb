{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139971a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T000000</th>\n",
       "      <th>2013-03-10 00:00:00</th>\n",
       "      <td>5207.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 00:30:00</th>\n",
       "      <td>5002.275879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 01:00:00</th>\n",
       "      <td>4747.569824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 01:30:00</th>\n",
       "      <td>4544.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 02:00:00</th>\n",
       "      <td>4425.952148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  target\n",
       "item_id timestamp                       \n",
       "T000000 2013-03-10 00:00:00  5207.959961\n",
       "        2013-03-10 00:30:00  5002.275879\n",
       "        2013-03-10 01:00:00  4747.569824\n",
       "        2013-03-10 01:30:00  4544.880859\n",
       "        2013-03-10 02:00:00  4425.952148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "data = TimeSeriesDataFrame.from_path(\n",
    "    \"https://autogluon.s3.amazonaws.com/datasets/timeseries/australian_electricity_subset/test.csv\"\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966a94ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting the dataframe index before generating the train/test split.\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250517_145051\"\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'c:\\workspace\\CrimeMap\\AutogluonModels\\ag-20250517_145051'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.12.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       2.89 GB / 15.70 GB (18.4%)\n",
      "Disk Space Avail:   70.88 GB / 475.50 GB (14.9%)\n",
      "===================================================\n",
      "Setting presets to: bolt_small\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': True,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: '30min'\n",
      "Provided train_data has 172800 rows, 5 time series. Median time series length is 34560 (min=34560, max=34560). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-05-17 16:50:52\n",
      "Models that will be trained: ['Chronos[bolt_small]']\n",
      "Training timeseries model Chronos[bolt_small]. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.\n",
      "\tThe pyarrow installation is not built with support for 'dataset' (DLL load failed while importing _dataset: Die angegebene Prozedur wurde nicht gefunden.)\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 6.10 s\n",
      "Trainer has no fit models that can predict.\n"
     ]
    }
   ],
   "source": [
    "prediction_length = 48\n",
    "train_data, test_data = data.train_test_split(prediction_length)\n",
    "\n",
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data, presets=\"bolt_small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb80557",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m predictor.plot(\n\u001b[32m      3\u001b[39m     data=data,\n\u001b[32m      4\u001b[39m     predictions=predictions,\n\u001b[32m      5\u001b[39m     item_ids=data.item_ids[:\u001b[32m2\u001b[39m],\n\u001b[32m      6\u001b[39m     max_history_length=\u001b[32m200\u001b[39m,\n\u001b[32m      7\u001b[39m );\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\autogluon\\timeseries\\predictor.py:859\u001b[39m, in \u001b[36mTimeSeriesPredictor.predict\u001b[39m\u001b[34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m known_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    858\u001b[39m     known_covariates = \u001b[38;5;28mself\u001b[39m._to_data_frame(known_covariates)\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(TimeSeriesDataFrame, predictions.reindex(original_item_id_order, level=ITEMID))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\autogluon\\timeseries\\learner.py:174\u001b[39m, in \u001b[36mTimeSeriesLearner.predict\u001b[39m\u001b[34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m known_covariates = \u001b[38;5;28mself\u001b[39m.feature_generator.transform_future_known_covariates(known_covariates)\n\u001b[32m    173\u001b[39m known_covariates = \u001b[38;5;28mself\u001b[39m._align_covariates_with_forecast_index(known_covariates=known_covariates, data=data)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\autogluon\\timeseries\\trainer.py:778\u001b[39m, in \u001b[36mTimeSeriesTrainer.predict\u001b[39m\u001b[34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    772\u001b[39m     data: TimeSeriesDataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m     random_seed: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    777\u001b[39m ) -> TimeSeriesDataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     model_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_model_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m     model_pred_dict, _ = \u001b[38;5;28mself\u001b[39m.get_model_pred_dict(\n\u001b[32m    780\u001b[39m         model_names=[model_name],\n\u001b[32m    781\u001b[39m         data=data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    784\u001b[39m         random_seed=random_seed,\n\u001b[32m    785\u001b[39m     )\n\u001b[32m    786\u001b[39m     predictions = model_pred_dict[model_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\autogluon\\timeseries\\trainer.py:754\u001b[39m, in \u001b[36mTimeSeriesTrainer._get_model_for_prediction\u001b[39m\u001b[34m(self, model, verbose)\u001b[39m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m         best_model_name: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_best = best_model_name\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\CrimeMap\\CrimeMap_venv\\Lib\\site-packages\\autogluon\\timeseries\\trainer.py:214\u001b[39m, in \u001b[36mTimeSeriesTrainer.get_model_best\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m models = \u001b[38;5;28mself\u001b[39m.get_model_names()\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTrainer has no fit models that can predict.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) == \u001b[32m1\u001b[39m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data)\n",
    "predictor.plot(\n",
    "    data=data,\n",
    "    predictions=predictions,\n",
    "    item_ids=data.item_ids[:2],\n",
    "    max_history_length=200,\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrimeMap_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
